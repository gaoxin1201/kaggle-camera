{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import env\n",
    "from utils import (KaggleCameraDataset, one_hot_decision_function, \n",
    "                   unhot, softmax, inv_softmax, progress_iter, RNG, float32)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_proba(proba_path):\n",
    "    return pd.read_csv(proba_path).as_matrix(columns=map(str, range(10)))\n",
    "\n",
    "\n",
    "def avg_proba(*proba_paths, **kwargs):\n",
    "    print kwargs.get('weights', None)\n",
    "    #return np.exp(np.average([np.log(1e-16 + get_proba(path)) for path in proba_paths], axis=0, weights=kwargs.get('weights', None)))\n",
    "    P = softmax(np.average([inv_softmax(get_proba(path)) for path in proba_paths], axis=0, weights=kwargs.get('weights', None)))\n",
    "    return P\n",
    "\n",
    "\n",
    "def proba_to_subm(proba, subm_path):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    proba : (2640, 10) np.ndarray\n",
    "    \"\"\"\n",
    "    test_dataset = KaggleCameraDataset('../data/', train=False, lazy=True)\n",
    "    fnames = [os.path.split(fname)[-1] for fname in test_dataset.X]\n",
    "    index_pred = unhot(one_hot_decision_function(proba))\n",
    "    data = {'fname': fnames,\n",
    "            'camera': [KaggleCameraDataset.target_labels()[int(c)] for c in index_pred]}\n",
    "    df = pd.DataFrame(data, columns=['fname', 'camera'])\n",
    "    df.to_csv(subm_path, index=False)\n",
    "    \n",
    "\n",
    "def get_diff(subm_path1, subm_path2):\n",
    "    df1 = pd.read_csv(subm_path1)\n",
    "    df2 = pd.read_csv(subm_path2)\n",
    "    return (df1 != df2)['camera'].sum()/2640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.30427057e-01,   4.84325022e-01,   5.16182883e-03],\n",
       "       [  4.63270843e-02,   1.69466971e-03,   1.10656278e-04],\n",
       "       [  1.59370884e-01,   1.33133292e-01,   2.71781767e-03]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = get_proba('../models/proba1.csv')\n",
    "P[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 average different predictions (from raw probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.30430266e-01,   4.46921155e-01,   3.23994139e-02, ...,\n",
       "          1.20126526e-03,   1.05716349e-02,   6.87616952e-02],\n",
       "       [  3.24848127e-02,   8.78940028e-02,   4.32265330e-03, ...,\n",
       "          8.78389790e-04,   6.59955412e-01,   4.10077199e-02],\n",
       "       [  1.20631762e-01,   1.52186640e-01,   1.57862445e-03, ...,\n",
       "          1.04656043e-03,   1.19606800e-01,   5.12661040e-01],\n",
       "       ..., \n",
       "       [  1.16247602e-01,   4.08802994e-01,   5.17931608e-02, ...,\n",
       "          3.80601780e-02,   1.16218922e-02,   1.64976966e-01],\n",
       "       [  4.96196985e-01,   4.23220114e-03,   2.48291728e-03, ...,\n",
       "          3.88299840e-01,   1.79937498e-02,   6.91680338e-02],\n",
       "       [  2.15672876e-01,   3.66537021e-02,   2.02466367e-03, ...,\n",
       "          1.86312740e-05,   3.95222452e-02,   1.85410858e-02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = avg_proba('../models/proba1.csv', \n",
    "              '../models/proba_best.csv', \n",
    "               weights=[1., 1.])\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2 convert proba to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba_to_subm(Q, 'subm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3 how predictions differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4693181818181818"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_diff('../models/submission1.csv', '../models/submission_best.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# average everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generations 1, 2 -> 0.913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.25, 0.25, 1.0, 1.0, 1.0, 0.25, 0.1, 2.0, 1.5, 1.5, 2.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.5]\n"
     ]
    }
   ],
   "source": [
    "proba_dirs = [\n",
    "    #\n",
    "    ## 1th-generation\n",
    "    ### \n",
    "    # DenseNet no augmentation (512x512 crops)\n",
    "    (0.1, '0.579-#15'),\n",
    "    # DenseNet + random horiz flips only\n",
    "    (0.25, '0.691-#23-tta-horiz'),\n",
    "    # DenseNet + random crops + aug + TTA x 10 + LR restart\n",
    "    (0.25, '0.732-#23-tta10'),\n",
    "    (1., '0.750-#25'),\n",
    "    # ... but trained on 256x256 crops\n",
    "    (1., '0.742-#36'),\n",
    "    # ... but trained using Hinge Loss (512x512)\n",
    "    (1., '0.750-#30'),\n",
    "    # CNN_Small 1-FC no aug\n",
    "    (0.25, '0.665-#39'),\n",
    "    # CNN_Small 2-FC (using best TTA) + SGD-m\n",
    "    (0.1, '0.517-#48'),\n",
    "    #\n",
    "    ## 2nd-generation\n",
    "    ###\n",
    "    (2.0, '0.859-d5-#95'), # ema.9 0.885 | RETEST WITH NEW TTA256 [+] -> 0.871\n",
    "    (1.5, 'dh5-#98'),      # ema.9 0.841 | RETEST WITH NEW TTA64  [+]\n",
    "    (1.5, 'r3-#100'),      # ema.9 0.845 | RETEST WITH NEW TTA64  [-]\n",
    "    (2.0, 'R3-#103'),      # ema.9 0.877 | RETEST WITH NEW TTA128 [+]\n",
    "    (1.0, 'c6-#105'),      # ema.9 0.791 | RETEST WITH NEW TTA32  [+]\n",
    "    \n",
    "#     # 3rd-generation\n",
    "#     ## \n",
    "#     (0.75, 'dc1-#131'),  # TTA64 | ema.9 0.9126\n",
    "#     (1.0, 'dhc1-#132'), # TTA32 | ema.9 0.8822\n",
    "#     (1.0, 'D1-#135'),   # TTA32 | ema.9 ~0.89\n",
    "#     (1.0, 'Rc1-#133'),  # TTA32 | ema.9 0.9004\n",
    "#     (1.0, 'Z1-#134'),   # TTA32 | ema.9 0.8995\n",
    "#     (0.5, 'cc1-#137'),  # TTA32 | ema.9 0.7948\n",
    "]\n",
    "weights, dirs = zip(*proba_dirs)\n",
    "P = avg_proba(*map(lambda p: '../submissions/{0}/proba.csv'.format(p), dirs), \n",
    "              weights=list(weights))\n",
    "proba_to_subm(P, '../submissions/averaged_gen12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generation 4th (blending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "proba_dirs = [\n",
    "    # D121 256x256 d=0 weighted\n",
    "    (1., '0.960-d-#181'),\n",
    "    # BEST FROM D121 d=\n",
    "    (0.5, '0.949-dw-0.3-#194'),\n",
    "    # D121 512x512 d=0.1 (unw.)\n",
    "    (0.5, '0.946-d-512-#191'),\n",
    "    # R50 512x512 d=0.2 (unw.)\n",
    "    (0.25, 'R-512-#189'),\n",
    "    # R50 256x256 d=0 (unw.)\n",
    "    (0.25, 'R-#190'),\n",
    "    # TODO: C2 * 0.25\n",
    "]\n",
    "weights, dirs = zip(*proba_dirs)\n",
    "P = avg_proba(*map(lambda p: '../submissions/{0}/proba.csv'.format(p), dirs), \n",
    "              weights=list(weights))\n",
    "proba_to_subm(P, '../submissions/averaged_gen4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average all approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba_dirs = [\n",
    "    #\n",
    "    ##\n",
    "    ### generations 1, 2\n",
    "    (1., '0.913-#109-recomp'),   \n",
    "]\n",
    "\n",
    "weights, dirs = zip(*proba_dirs)\n",
    "P = avg_proba(*map(lambda p: '../submissions/{0}/proba.csv'.format(p), dirs), \n",
    "              weights=list(weights))\n",
    "proba_to_subm(P, '../submissions/all_averaged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pseudo-labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248, 103, 237, 242, 236, 252, 251, 206, 223, 229]\n"
     ]
    }
   ],
   "source": [
    "P = get_proba('../submissions/0.960-d-#181/proba.csv')\n",
    "THRESHOLD = 0.99\n",
    "pseudo_ind = {}\n",
    "for c in xrange(10):\n",
    "    c_ind = np.arange(len(P))[P[:,c] > THRESHOLD].tolist()\n",
    "    c_ind.sort(key=lambda i: -P[i, c]) # sorted such that c_ind[0] is the most confident image\n",
    "    pseudo_ind[c] = c_ind\n",
    "print map(len, pseudo_ind.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1742, 361, 1386, 963, 2436]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_ind[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2138, 2171, 2220]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_ind[7][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/pseudo_ind.json', 'w') as f:\n",
    "    json.dump(pseudo_ind, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/pseudo_ind.json') as f:\n",
    "    pseudo_ind = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1742, 361, 1386, 963, 2436]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_ind['0'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and save most confident images for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = KaggleCameraDataset('../data/', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_PSEUDO_VAL_PER_CLASS = 24\n",
    "N_PSEUDO_VAL = N_PSEUDO_VAL_PER_CLASS * 10\n",
    "X_pseudo_val = np.zeros((N_PSEUDO_VAL, 512, 512, 3), dtype=np.uint8)\n",
    "\n",
    "pos = 0\n",
    "y_pseudo_val = []\n",
    "manip = []\n",
    "for c in xrange(10):\n",
    "    for i in pseudo_ind[str(c)][:N_PSEUDO_VAL_PER_CLASS]:\n",
    "        (x, m), _ = test_dataset[i]\n",
    "        X_pseudo_val[pos] = np.asarray(x, dtype=np.uint8)\n",
    "        pos += 1\n",
    "        manip.append(m)\n",
    "        y_pseudo_val.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with existing validation, shuffle and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_val = np.load('../data/X_val_val.npy')\n",
    "y_val_val = np.load('../data/y_val_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 512, 512, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "X_val_with_pseudo = np.concatenate((X_val_val, X_pseudo_val))\n",
    "print X_val_with_pseudo.shape, X_val_with_pseudo.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480,) int64\n"
     ]
    }
   ],
   "source": [
    "y_val_with_pseudo = np.concatenate((y_val_val, np.asarray(y_pseudo_val)))\n",
    "print y_val_with_pseudo.shape, y_val_with_pseudo.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 1) float32\n"
     ]
    }
   ],
   "source": [
    "manip_with_pseudo = np.concatenate((np.asarray([float32(0.)]*len(y_val_val)), manip))\n",
    "print manip_with_pseudo.shape, manip_with_pseudo.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(480)\n",
    "RNG(seed=1234).shuffle(ind)\n",
    "X_val_with_pseudo = X_val_with_pseudo[ind]\n",
    "y_val_with_pseudo = y_val_with_pseudo[ind]\n",
    "manip_with_pseudo = manip_with_pseudo[ind]\n",
    "np.save('../data/X_val_with_pseudo.npy', X_val_with_pseudo)\n",
    "np.save('../data/y_val_with_pseudo.npy', y_val_with_pseudo)\n",
    "np.save('../data/manip_with_pseudo.npy', manip_with_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68.], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(manip_with_pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float32(0.)[0] < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remaining pseudo-labels for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 79, 213, 218, 212, 228, 227, 182, 199, 205]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in xrange(10):\n",
    "    pseudo_ind[c] = pseudo_ind[str(c)][N_PSEUDO_VAL_PER_CLASS:]\n",
    "    del pseudo_ind[str(c)]\n",
    "PSEUDO_CLASSES = map(len, pseudo_ind.values())\n",
    "PSEUDO_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split into blocks of 8 images and save like regular train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 10, 27, 27, 26, 28, 28, 23, 25, 26]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSEUDO_BLOCK_SIZE = 8\n",
    "N_PSEUDO_BLOCKS = [int(np.round(t/float(PSEUDO_BLOCK_SIZE))) for t in PSEUDO_CLASSES]\n",
    "N_PSEUDO_BLOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in xrange(10):\n",
    "    c_ind = pseudo_ind[c]\n",
    "    RNG(seed=8888 + c).shuffle(c_ind)\n",
    "    class_blocks = []\n",
    "    class_manip = []\n",
    "    for _ in xrange(N_PSEUDO_BLOCKS[c]):\n",
    "        class_blocks.append([])\n",
    "        class_manip.append([])\n",
    "    pos = 0\n",
    "    for i in progress_iter(c_ind, True):\n",
    "        (x, m), _ = test_dataset[i]\n",
    "        x = np.asarray(x, dtype=np.uint8)\n",
    "        class_blocks[pos % N_PSEUDO_BLOCKS[c]].append(x)\n",
    "        class_manip[pos % N_PSEUDO_BLOCKS[c]].append(m)\n",
    "        pos += 1\n",
    "    for b in xrange(N_PSEUDO_BLOCKS[c]):\n",
    "        np.save('../data/X_pseudo_{0}_{1}.npy'.format(c, b), np.asarray(class_blocks[b], dtype=np.uint8))\n",
    "        np.save('../data/manip_pseudo_{0}_{1}.npy'.format(c, b), np.asarray(class_manip[b], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manip ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n",
      "[ 972.]\n"
     ]
    }
   ],
   "source": [
    "manip = []\n",
    "for c in xrange(10):\n",
    "    c_ind = pseudo_ind[c]\n",
    "    for i in c_ind:\n",
    "        (_, m), _ = test_dataset[i]\n",
    "        manip.append(m)\n",
    "print len(manip)\n",
    "print sum(manip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835\n"
     ]
    }
   ],
   "source": [
    "# P from 0.908-#109\n",
    "ind = np.arange(2640)[P.max(axis=1) > 0.8]\n",
    "print len(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = KaggleCameraDataset('../data/', train=False)\n",
    "X = np.zeros((len(ind), 512, 512, 3), dtype=np.uint8)\n",
    "pos = 0\n",
    "for i in ind:\n",
    "    x = Image.open(test_data.X[i])\n",
    "    x = np.array(x, dtype=np.uint8)\n",
    "    X[pos, ...] = x\n",
    "    pos += 1\n",
    "y = np.argmax(P, axis=1)[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratifically split into ~335 for validation and 500 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=500, random_state=1337)\n",
    "train_ind, val_ind = list(sss.split(X, y))[0]\n",
    "print train_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/X_pseudo_train.npy', X[train_ind])\n",
    "np.save('../data/y_pseudo_train.npy', y[train_ind])\n",
    "np.save('../data/X_pseudo_val.npy', X[val_ind])\n",
    "np.save('../data/y_pseudo_val.npy', y[val_ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
